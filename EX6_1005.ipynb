{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNP32x5t58pW78XPE5wt6OX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-geun-hyeong/CUDA/blob/main/EX6_1005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaL5P6tC0BwT",
        "outputId": "55d9a0e2-865a-4393-f80c-4db68ddd99b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct  7 07:22:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaifEEP21WAc",
        "outputId": "3b10a7eb-ba03-4d3f-c3b1-bb0bc13166dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU위에서 벡터의 합 계산"
      ],
      "metadata": {
        "id": "pxYlwocr1zoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition.cu\n",
        "#include<stdio.h>\n",
        "#define N 512\n",
        "\n",
        "void host_add(int *a, int *b, int *c);\n",
        "void fill_array(int *data);\n",
        "void print_output(int *a, int *b, int *c);\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  int *a, *b, *c;\n",
        "  a = (int*)malloc(N*sizeof(int)); fill_array(a);\n",
        "  b = (int*)malloc(N*sizeof(int)); fill_array(b);\n",
        "  c = (int*)malloc(N*sizeof(int));\n",
        "\n",
        "  host_add(a,b,c);\n",
        "  print_output(a,b,c);\n",
        "  free(a); free(b); free(c);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "void host_add(int *a, int *b, int *c)\n",
        "{\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    c[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void fill_array(int *data)\n",
        "{\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    data[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "void print_output(int *a, int *b, int *c)\n",
        "{\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    printf(\"%d + %d = %d\\n\", a[i],b[i],c[i]);\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ-FaDLL1sOS",
        "outputId": "93fe7d0b-36f8-4b5b-ce19-f0c35d0840b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vector_add_cpu vector_addition.cu"
      ],
      "metadata": {
        "id": "PeVJtk-d3Bww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add_cpu"
      ],
      "metadata": {
        "id": "c0mnCXAi3B9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GPU위에서 벡터의 합(블록 개수 N, 각각 1개의 Thread 포함)"
      ],
      "metadata": {
        "id": "K9j6Vdvw3ZEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition2.cu\n",
        "#include<stdio.h>\n",
        "#define N 512\n",
        "\n",
        "__global__ void device_add(int *a, int *b , int *c)\n",
        "{\n",
        "  c[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "}\n",
        "\n",
        "void fill_array(int *data);\n",
        "void print_output(int *a, int *b, int *c);\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  int *a, *b, *c;\n",
        "  int *dev_a, *dev_b, *dev_c;\n",
        "  a = (int*)malloc(N*sizeof(int)); fill_array(a);\n",
        "  b = (int*)malloc(N*sizeof(int)); fill_array(b);\n",
        "  c = (int*)malloc(N*sizeof(int));\n",
        "\n",
        "  cudaMalloc((void**)&dev_a, N*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_b, N*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_c, N*sizeof(int));\n",
        "\n",
        "  cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "  \n",
        "  device_add<<<N,1>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        "  cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  print_output(a,b,c);\n",
        "\n",
        "  free(a); free(b); free(c);\n",
        "  cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c);\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "void fill_array(int *data)\n",
        "{\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    data[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "void print_output(int *a, int *b, int *c)\n",
        "{\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    printf(\"%d + %d = %d\\n\", a[i],b[i],c[i]);\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5pjHylb3HQL",
        "outputId": "9f07c2ec-9182-42e9-9370-c3d85c0cdf8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vector_addition_gpu vector_addition2.cu"
      ],
      "metadata": {
        "id": "PLvYlceT3Nd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_addition_gpu"
      ],
      "metadata": {
        "id": "_h9z9BKJ4i6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition_gpu_block_thread.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#define N 32\n",
        "\n",
        "__global__ void device_add(int *a, int *b, int *c, int *id)\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  id[idx] = idx;\n",
        "  c[idx] = a[idx] + b[idx];\n",
        "\n",
        "  // idx 순서가 아닌 무작위적으로 병렬처리 됨을 확인할 수 있다.\n",
        "  printf(\"[Thread Id: %d] => [ThreadIdx.x: %d] + [BlockIdx.x: %d] x [BlockDim.x: %d]\\n\", idx, threadIdx.x, blockIdx.x, blockDim.x); \n",
        "}\n",
        "\n",
        "void fill_array(int *data);\n",
        "void print_output(int *a, int *b, int *c, int *id);\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  int *a, *b, *c, *id;\n",
        "  int *dev_a, *dev_b, *dev_c, *dev_id;\n",
        "  a = (int*)malloc(N*sizeof(int)); fill_array(a);\n",
        "  b = (int*)malloc(N*sizeof(int)); fill_array(b);\n",
        "  c = (int*)malloc(N*sizeof(int));\n",
        "  id = (int*)malloc(N*sizeof(int));\n",
        "\n",
        "  cudaMalloc((void**)&dev_a, N*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_b, N*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_c, N*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_id, N*sizeof(int));\n",
        "\n",
        "  cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "  \n",
        "  int thread_per_block = 4;\n",
        "  int N_blocks = N/thread_per_block;\n",
        "\n",
        "  device_add<<<N_blocks,thread_per_block>>>(dev_a, dev_b, dev_c, dev_id);\n",
        "\n",
        "  cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(id, dev_id, N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  \n",
        "  print_output(a,b,c,id);\n",
        "\n",
        "  free(a); free(b); free(c), free(id);\n",
        "  cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c), cudaFree(dev_id);\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "void fill_array(int *data)\n",
        "{\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    data[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "void print_output(int *a, int *b, int *c, int* id)\n",
        "{ \n",
        "  printf(\"===========================================================\\n\");\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    printf(\"[ThreadId: %d ]%d + %d = %d\\n\", id[i],a[i],b[i],c[i]);\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAGKfY4ZqyaN",
        "outputId": "f2dc33d6-6280-46b1-9e57-910fce4a7ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition_gpu_block_thread.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vector_addition_gpu_block_thread vector_addition_gpu_block_thread.cu"
      ],
      "metadata": {
        "id": "nSyLOPecup-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_addition_gpu_block_thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg3eEf4AutRk",
        "outputId": "ff6577f1-304e-443d-c348-0c90f1e53af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Thread Id: 24] => [ThreadIdx.x: 0] + [BlockIdx.x: 6] x [BlockDim.x: 4]\n",
            "[Thread Id: 25] => [ThreadIdx.x: 1] + [BlockIdx.x: 6] x [BlockDim.x: 4]\n",
            "[Thread Id: 26] => [ThreadIdx.x: 2] + [BlockIdx.x: 6] x [BlockDim.x: 4]\n",
            "[Thread Id: 27] => [ThreadIdx.x: 3] + [BlockIdx.x: 6] x [BlockDim.x: 4]\n",
            "[Thread Id: 16] => [ThreadIdx.x: 0] + [BlockIdx.x: 4] x [BlockDim.x: 4]\n",
            "[Thread Id: 17] => [ThreadIdx.x: 1] + [BlockIdx.x: 4] x [BlockDim.x: 4]\n",
            "[Thread Id: 18] => [ThreadIdx.x: 2] + [BlockIdx.x: 4] x [BlockDim.x: 4]\n",
            "[Thread Id: 19] => [ThreadIdx.x: 3] + [BlockIdx.x: 4] x [BlockDim.x: 4]\n",
            "[Thread Id: 4] => [ThreadIdx.x: 0] + [BlockIdx.x: 1] x [BlockDim.x: 4]\n",
            "[Thread Id: 5] => [ThreadIdx.x: 1] + [BlockIdx.x: 1] x [BlockDim.x: 4]\n",
            "[Thread Id: 6] => [ThreadIdx.x: 2] + [BlockIdx.x: 1] x [BlockDim.x: 4]\n",
            "[Thread Id: 7] => [ThreadIdx.x: 3] + [BlockIdx.x: 1] x [BlockDim.x: 4]\n",
            "[Thread Id: 28] => [ThreadIdx.x: 0] + [BlockIdx.x: 7] x [BlockDim.x: 4]\n",
            "[Thread Id: 29] => [ThreadIdx.x: 1] + [BlockIdx.x: 7] x [BlockDim.x: 4]\n",
            "[Thread Id: 30] => [ThreadIdx.x: 2] + [BlockIdx.x: 7] x [BlockDim.x: 4]\n",
            "[Thread Id: 31] => [ThreadIdx.x: 3] + [BlockIdx.x: 7] x [BlockDim.x: 4]\n",
            "[Thread Id: 12] => [ThreadIdx.x: 0] + [BlockIdx.x: 3] x [BlockDim.x: 4]\n",
            "[Thread Id: 13] => [ThreadIdx.x: 1] + [BlockIdx.x: 3] x [BlockDim.x: 4]\n",
            "[Thread Id: 14] => [ThreadIdx.x: 2] + [BlockIdx.x: 3] x [BlockDim.x: 4]\n",
            "[Thread Id: 15] => [ThreadIdx.x: 3] + [BlockIdx.x: 3] x [BlockDim.x: 4]\n",
            "[Thread Id: 20] => [ThreadIdx.x: 0] + [BlockIdx.x: 5] x [BlockDim.x: 4]\n",
            "[Thread Id: 21] => [ThreadIdx.x: 1] + [BlockIdx.x: 5] x [BlockDim.x: 4]\n",
            "[Thread Id: 22] => [ThreadIdx.x: 2] + [BlockIdx.x: 5] x [BlockDim.x: 4]\n",
            "[Thread Id: 23] => [ThreadIdx.x: 3] + [BlockIdx.x: 5] x [BlockDim.x: 4]\n",
            "[Thread Id: 8] => [ThreadIdx.x: 0] + [BlockIdx.x: 2] x [BlockDim.x: 4]\n",
            "[Thread Id: 9] => [ThreadIdx.x: 1] + [BlockIdx.x: 2] x [BlockDim.x: 4]\n",
            "[Thread Id: 10] => [ThreadIdx.x: 2] + [BlockIdx.x: 2] x [BlockDim.x: 4]\n",
            "[Thread Id: 11] => [ThreadIdx.x: 3] + [BlockIdx.x: 2] x [BlockDim.x: 4]\n",
            "[Thread Id: 0] => [ThreadIdx.x: 0] + [BlockIdx.x: 0] x [BlockDim.x: 4]\n",
            "[Thread Id: 1] => [ThreadIdx.x: 1] + [BlockIdx.x: 0] x [BlockDim.x: 4]\n",
            "[Thread Id: 2] => [ThreadIdx.x: 2] + [BlockIdx.x: 0] x [BlockDim.x: 4]\n",
            "[Thread Id: 3] => [ThreadIdx.x: 3] + [BlockIdx.x: 0] x [BlockDim.x: 4]\n",
            "===========================================================\n",
            "[ThreadId: 0 ]0 + 0 = 0\n",
            "[ThreadId: 1 ]1 + 1 = 2\n",
            "[ThreadId: 2 ]2 + 2 = 4\n",
            "[ThreadId: 3 ]3 + 3 = 6\n",
            "[ThreadId: 4 ]4 + 4 = 8\n",
            "[ThreadId: 5 ]5 + 5 = 10\n",
            "[ThreadId: 6 ]6 + 6 = 12\n",
            "[ThreadId: 7 ]7 + 7 = 14\n",
            "[ThreadId: 8 ]8 + 8 = 16\n",
            "[ThreadId: 9 ]9 + 9 = 18\n",
            "[ThreadId: 10 ]10 + 10 = 20\n",
            "[ThreadId: 11 ]11 + 11 = 22\n",
            "[ThreadId: 12 ]12 + 12 = 24\n",
            "[ThreadId: 13 ]13 + 13 = 26\n",
            "[ThreadId: 14 ]14 + 14 = 28\n",
            "[ThreadId: 15 ]15 + 15 = 30\n",
            "[ThreadId: 16 ]16 + 16 = 32\n",
            "[ThreadId: 17 ]17 + 17 = 34\n",
            "[ThreadId: 18 ]18 + 18 = 36\n",
            "[ThreadId: 19 ]19 + 19 = 38\n",
            "[ThreadId: 20 ]20 + 20 = 40\n",
            "[ThreadId: 21 ]21 + 21 = 42\n",
            "[ThreadId: 22 ]22 + 22 = 44\n",
            "[ThreadId: 23 ]23 + 23 = 46\n",
            "[ThreadId: 24 ]24 + 24 = 48\n",
            "[ThreadId: 25 ]25 + 25 = 50\n",
            "[ThreadId: 26 ]26 + 26 = 52\n",
            "[ThreadId: 27 ]27 + 27 = 54\n",
            "[ThreadId: 28 ]28 + 28 = 56\n",
            "[ThreadId: 29 ]29 + 29 = 58\n",
            "[ThreadId: 30 ]30 + 30 = 60\n",
            "[ThreadId: 31 ]31 + 31 = 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 유휴코어 최소화\n",
        "- 미리 그래픽카드 성능향상을 생각하지 않고 블록 수를 적게 만들면 유휴 SM이 늘어나게 됨\n",
        "- 가급적 많은 블록 및 스레드를 생성할 것 "
      ],
      "metadata": {
        "id": "eaciGyPYu_Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition_large.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void device_add(int *a, int *b, int *c)\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  c[idx] = a[idx] + b[idx];\n",
        "}\n",
        "\n",
        "void fill_array(int *data);\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int size = 512*65535;\n",
        "  const int BufferSize = size*sizeof(int);\n",
        "\n",
        "  int *a, *b, *c;\n",
        "  int *dev_a, *dev_b, *dev_c;\n",
        "  a = (int*)malloc(BufferSize); fill_array(a);\n",
        "  b = (int*)malloc(BufferSize); fill_array(b);\n",
        "  c = (int*)malloc(BufferSize);\n",
        "\n",
        "  cudaMalloc((void**)&dev_a, BufferSize);\n",
        "  cudaMalloc((void**)&dev_b, BufferSize);\n",
        "  cudaMalloc((void**)&dev_c, BufferSize);\n",
        "\n",
        "  cudaMemcpy(dev_a, a, BufferSize, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(dev_b, b, BufferSize, cudaMemcpyHostToDevice);\n",
        "  \n",
        "  int thread_per_block = 512;\n",
        "  int N_blocks = size/thread_per_block;\n",
        "\n",
        "  device_add<<<N_blocks,thread_per_block>>>(dev_a, dev_b, dev_c);\n",
        "  cudaMemcpy(c, dev_c, BufferSize, cudaMemcpyDeviceToHost);\n",
        "  for(int i = 0; i < 20; i++)\n",
        "    printf(\" Result[%d] : %d\\n\",i,c[i]);\n",
        "  \n",
        "  printf(\" ......\\n\");\n",
        "  \n",
        "  for(int i = size-20; i < size; i++)\n",
        "    printf(\" Result[%d] : %d\\n\",i,c[i]);\n",
        "  \n",
        "  \n",
        "  free(a); free(b); free(c);\n",
        "  cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c);\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "void fill_array(int *data)\n",
        "{\n",
        "  const int N = 512*65535;\n",
        "  for(int i=0; i<N; i++)\n",
        "  {\n",
        "    data[i] = i;\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxrQzPPT68ve",
        "outputId": "925614ef-7e7f-4ffb-dd37-d861a4b3950c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition_large.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vector_addition_large vector_addition_large.cu"
      ],
      "metadata": {
        "id": "LJiJxJJd8pP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_addition_large"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccgcz_j88sp9",
        "outputId": "86410ba2-c6be-40bd-ff0c-de550227dfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result[0] : 0\n",
            " Result[1] : 2\n",
            " Result[2] : 4\n",
            " Result[3] : 6\n",
            " Result[4] : 8\n",
            " Result[5] : 10\n",
            " Result[6] : 12\n",
            " Result[7] : 14\n",
            " Result[8] : 16\n",
            " Result[9] : 18\n",
            " Result[10] : 20\n",
            " Result[11] : 22\n",
            " Result[12] : 24\n",
            " Result[13] : 26\n",
            " Result[14] : 28\n",
            " Result[15] : 30\n",
            " Result[16] : 32\n",
            " Result[17] : 34\n",
            " Result[18] : 36\n",
            " Result[19] : 38\n",
            " ......\n",
            " Result[33553900] : 67107800\n",
            " Result[33553901] : 67107802\n",
            " Result[33553902] : 67107804\n",
            " Result[33553903] : 67107806\n",
            " Result[33553904] : 67107808\n",
            " Result[33553905] : 67107810\n",
            " Result[33553906] : 67107812\n",
            " Result[33553907] : 67107814\n",
            " Result[33553908] : 67107816\n",
            " Result[33553909] : 67107818\n",
            " Result[33553910] : 67107820\n",
            " Result[33553911] : 67107822\n",
            " Result[33553912] : 67107824\n",
            " Result[33553913] : 67107826\n",
            " Result[33553914] : 67107828\n",
            " Result[33553915] : 67107830\n",
            " Result[33553916] : 67107832\n",
            " Result[33553917] : 67107834\n",
            " Result[33553918] : 67107836\n",
            " Result[33553919] : 67107838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 블록 및 스레드 동적 설정\n",
        "- G80기준 블록 생성 최대개수 : 65535 개\n",
        "- G80기준 블록당 스레드 생성 최대개수 : 512\n",
        "- 만약 원소수 65535*512*3개가 있는 벡터합은 인덱스 할당을 어떻게 해주어야 할까?"
      ],
      "metadata": {
        "id": "FrEmab3j9Dv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition_shift.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void device_add(int *a, int *b, int *c, int arr_cnt)\n",
        "{  \n",
        "  int tid = 0;\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  while(tid < 3)\n",
        "  {\n",
        "    c[tid*(arr_cnt/3) + idx] = a[tid*(arr_cnt/3) + idx] + b[tid*(arr_cnt/3) + idx];\n",
        "    tid +=1;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int *a, *b, *c;\n",
        "  int *dev_a, *dev_b, *dev_c;\n",
        "\n",
        "  int arr_cnt = 65535*512*3;\n",
        "\n",
        "  a = (int*)malloc(arr_cnt*sizeof(int)); \n",
        "  b = (int*)malloc(arr_cnt*sizeof(int)); \n",
        "  c = (int*)malloc(arr_cnt*sizeof(int));\n",
        "\n",
        "  cudaMalloc((void**)&dev_a, arr_cnt*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_b, arr_cnt*sizeof(int));\n",
        "  cudaMalloc((void**)&dev_c, arr_cnt*sizeof(int));\n",
        "  \n",
        "  for (int i=0; i<arr_cnt; i++) {\n",
        "    a[i] = i;\n",
        "    b[i] = i;\n",
        "  }\n",
        "  \n",
        "  cudaMemcpy(dev_a, a, arr_cnt*sizeof(int), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(dev_b, b, arr_cnt*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int thread_per_block = 512;\n",
        "  int N_blocks = 65535;\n",
        "\n",
        "  device_add<<<N_blocks, thread_per_block>>>(dev_a, dev_b, dev_c, arr_cnt);\n",
        "  cudaMemcpy(c, dev_c, arr_cnt*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  \n",
        "  bool success = true;\n",
        "  for(int i = 0; i < arr_cnt; i++)\n",
        "  {\n",
        "    if((a[i]+b[i])!=c[i])\n",
        "    {\n",
        "      //printf(\"Error: %d + %d != %d\\n\", a[i],b[i],c[i]);\n",
        "      success=false;\n",
        "    }\n",
        "  }\n",
        "  if(success) printf(\"we did it\\n\");\n",
        "  else printf(\"we fail\\n\");\n",
        "\n",
        "  free(a); free(b); free(c);\n",
        "  cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c);\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sENpsRrs9702",
        "outputId": "8544ab07-500c-4867-c4e0-4df318e57cb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_addition_shift.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!nvcc -o vector_addition_shift vector_addition_shift.cu "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d962pT8jB8R1",
        "outputId": "5ee2db03-f4ec-46d8-bbec-f26456c0712c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_addition_shift"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EepFU1hDCA30",
        "outputId": "d7118f11-b1e5-4aea-991e-7dc1619153c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we did it\n"
          ]
        }
      ]
    }
  ]
}